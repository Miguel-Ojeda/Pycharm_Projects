{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35597f13-caa0-4f30-acb4-74fe2d2111e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c21fb99-df58-4597-8fab-efdba3b589bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape\n",
    "# SOn muy pocos datos, 404 para entrenar y 102 para testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274ad9f4-4afa-4eb9-94a4-15364fb51721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n",
    "# Cada sample es un vector con 13 características...\n",
    "# such as per capita crime rate, average number of rooms per dwelling, accessibility to highways, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52fc6262-5487-474b-a62e-ae7ba02d479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[0]  # es como el precio, en miles de dólares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310e70fe-47ae-4081-a008-88dcb86d7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problema... las componentes de train_data tienen rango muy dispares!!!\n",
    "# Se suele normalizar: para cada feature we subtract the mean of the feature and divide by the standard deviation,\n",
    "# so that the feature is centered around 0 and has a unit standard deviation. This is easily done in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d162c247-ee9b-43ab-97bb-5a873abad4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(datos: np.ndarray) -> np.ndarray:\n",
    "    mean = datos.mean(axis=0)  # para que haga la media de cada columna!!! de cada una de las 13 características\n",
    "    std = datos.std(axis=0)  # es el vector con las desviaciones estándar de cada columna\n",
    "    datos -= mean  # nos centra en la media, cada columna con su media\n",
    "    datos /= std\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e06187ba-4bde-4ff4-bb7b-cb42c835fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalize(train_data)\n",
    "test_data = normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06037826-c7f4-47c3-8178-7c2d8ae68c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "       -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "        1.14850044,  0.44807713,  0.8252202 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]  # el mismo sample que mostramos antes, totalmente normalizado!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebade9bb-a4b3-42cf-9ecb-20583b4cf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf56cd06-35f8-408d-a213-ee2e1d10a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesitaremos instanciar el modelo varias veces, así que crearemos con una función\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e98424d-7ced-4bdc-b7a5-5c7b9553d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observar que la capa de salida no tiene activación... esto es normal en los modelos de regresión\n",
    "# por ejemplo, si utilizamo sigmoide estaríamos restringiendo entre 0 y 1, etc\n",
    "# El error usado es mse: mean squared error, clásico en estos problemas de regresión!!\n",
    "# Como métrica usaremos mae, mean absolute error (por ejemplo, si fuera 0.5 significaría un error absoluto de 500 dólares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0f3b2-0c07-4234-a2d9-5efa1fd467bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
